{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdityaKumbhar21/Natural_Language_Processing/blob/main/Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install gensim if you haven't already\n",
        "# !pip install gensim\n",
        "\n",
        "# Import necessary libraries\n",
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output, especially from gensim\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## 2. Download and Load the Pre-trained Google News Word2Vec Model\n",
        "\n",
        "The `gensim.downloader` module provides access to various pre-trained models. We'll use the 'word2vec-google-news-300' model, which contains 300-dimensional vectors for 3 million words and phrases.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "# Define the model name\n",
        "model_name = \"word2vec-google-news-300\"\n",
        "\n",
        "print(f\"Attempting to download and load the '{model_name}' model. This may take a while...\")\n",
        "\n",
        "try:\n",
        "    # Download the model (if not already downloaded)\n",
        "    # This will download to a default location (e.g., ~/.gensim/data)\n",
        "    wv = api.load(model_name)\n",
        "    print(f\"Model '{model_name}' loaded successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    print(\"Please ensure you have enough disk space and a stable internet connection.\")\n",
        "    print(\"You might need to run this cell again if the download was interrupted.\")\n",
        "    wv = None # Set wv to None if loading fails to prevent errors in subsequent cells\n",
        "\n",
        "# Check if the model was loaded\n",
        "if wv:\n",
        "    print(f\"\\nNumber of words in vocabulary: {len(wv.key_to_index)}\")\n",
        "    print(f\"Vector dimension: {wv.vector_size}\")\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "## 3. Explore Word Vector Operations\n",
        "\n",
        "Now that the model is loaded, let's perform some common operations to understand how word embeddings capture semantic relationships.\n",
        "\"\"\"\n",
        "\n",
        "# %%\n",
        "if wv:\n",
        "    # 3.1 Get the vector for a specific word\n",
        "    word_vector_king = wv['king']\n",
        "    print(f\"Vector for 'king' (first 10 dimensions):\\n{word_vector_king[:10]}\\n\")\n",
        "\n",
        "    # 3.2 Find the most similar words\n",
        "    print(\"Words most similar to 'king':\")\n",
        "    for word, similarity in wv.most_similar('king'):\n",
        "        print(f\"  {word}: {similarity:.4f}\")\n",
        "    print(\"\\nWords most similar to 'car':\")\n",
        "    for word, similarity in wv.most_similar('car'):\n",
        "        print(f\"  {word}: {similarity:.4f}\")\n",
        "\n",
        "    # %% [markdown]\n",
        "    \"\"\"\n",
        "    ### 3.3 Word Analogies (King - Man + Woman = Queen)\n",
        "\n",
        "    One of the most famous demonstrations of Word2Vec's power is its ability to solve analogies.\n",
        "    \"\"\"\n",
        "\n",
        "    # %%\n",
        "    print(\"Solving analogy: 'king' - 'man' + 'woman' = ?\")\n",
        "    result = wv.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "    for word, similarity in result:\n",
        "        print(f\"  {word}: {similarity:.4f}\")\n",
        "\n",
        "    print(\"\\nSolving analogy: 'France' - 'Paris' + 'Rome' = ?\")\n",
        "    result = wv.most_similar(positive=['Rome', 'France'], negative=['Paris'])\n",
        "    for word, similarity in result:\n",
        "        print(f\"  {word}: {similarity:.4f}\")\n",
        "\n",
        "    # %% [markdown]\n",
        "    \"\"\"\n",
        "    ### 3.4 Calculate Similarity Between Two Words\n",
        "\n",
        "    You can directly calculate the cosine similarity between any two words in the vocabulary.\n",
        "    \"\"\"\n",
        "\n",
        "    # %%\n",
        "    word1 = 'good'\n",
        "    word2 = 'bad'\n",
        "    word3 = 'excellent'\n",
        "\n",
        "    similarity_good_bad = wv.similarity(word1, word2)\n",
        "    similarity_good_excellent = wv.similarity(word1, word3)\n",
        "\n",
        "    print(f\"Similarity between '{word1}' and '{word2}': {similarity_good_bad:.4f}\")\n",
        "    print(f\"Similarity between '{word1}' and '{word3}': {similarity_good_excellent:.4f}\")\n",
        "\n",
        "    # You can also get the raw vectors and compute cosine similarity manually\n",
        "    vec_good = wv[word1]\n",
        "    vec_bad = wv[word2]\n",
        "    manual_similarity = cosine_similarity(vec_good.reshape(1, -1), vec_bad.reshape(1, -1))[0][0]\n",
        "    print(f\"Manual cosine similarity between '{word1}' and '{word2}': {manual_similarity:.4f}\")\n",
        "\n",
        "    # %% [markdown]\n",
        "    \"\"\"\n",
        "    ### 3.5 Odd-One-Out (Does not fit)\n",
        "\n",
        "    Find the word that doesn't belong in a list.\n",
        "    \"\"\"\n",
        "\n",
        "    # %%\n",
        "    words = ['breakfast', 'lunch', 'dinner', 'car']\n",
        "    odd_one_out = wv.doesnt_match(words)\n",
        "    print(f\"Odd one out in {words}: '{odd_one_out}'\")\n",
        "\n",
        "    words_2 = ['apple', 'banana', 'orange', 'table']\n",
        "    odd_one_out_2 = wv.doesnt_match(words_2)\n",
        "    print(f\"Odd one out in {words_2}: '{odd_one_out_2}'\")\n",
        "\n",
        "    # %% [markdown]\n",
        "    \"\"\"\n",
        "    ### 3.6 Handling Out-of-Vocabulary (OOV) Words\n",
        "\n",
        "    What happens if you query a word not present in the model's vocabulary?\n",
        "    \"\"\"\n",
        "\n",
        "    # %%\n",
        "    oov_word = 'supercalifragilisticexpialidocious' # A very long, uncommon word\n",
        "    if oov_word in wv.key_to_index:\n",
        "        print(f\"'{oov_word}' is in the vocabulary.\")\n",
        "        print(wv[oov_word][:5])\n",
        "    else:\n",
        "        print(f\"'{oov_word}' is NOT in the vocabulary.\")\n",
        "        try:\n",
        "            # Attempting to access an OOV word will raise a KeyError\n",
        "            _ = wv[oov_word]\n",
        "        except KeyError as e:\n",
        "            print(f\"Caught expected error when accessing OOV word: {e}\")\n",
        "\n",
        "    # You can check for a word's presence before accessing it\n",
        "    common_word = 'computer'\n",
        "    if common_word in wv.key_to_index:\n",
        "        print(f\"\\n'{common_word}' is in the vocabulary.\")\n",
        "        print(wv[common_word][:5])\n",
        "    else:\n",
        "        print(f\"'{common_word}' is NOT in the vocabulary.\")\n",
        "else:\n",
        "    print(\"\\nModel was not loaded. Skipping demonstration of word vector operations.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "c8E0wKmLZ9P6"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}